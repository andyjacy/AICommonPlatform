version: '3.8'

# ==================== 轻量化本地 Docker 部署 ====================
# 支持三种运行模式：
# 1. 单机模式（仅 Web UI）- 用于快速本地测试
# 2. 完整模式（Web UI + 所有微服务）- 用于系统集成测试
# 3. 混合模式（Web UI + 指定服务）- 用于特定功能测试

# 用法：
# 模式1 - 单机（推荐用于本地开发）:
#   docker-compose -f docker-compose.lite.yml up --build
#   访问: http://localhost:3000
#
# 模式2 - 启用所有服务:
#   docker-compose -f docker-compose.lite.yml --profile all up --build
#
# 模式3 - 启用微服务:
#   docker-compose -f docker-compose.lite.yml --profile services up --build

services:
  # ==================== Web UI 服务（始终启动）====================
  # 这是主应用界面，支持本地 SQLite 和 standalone 模式
  
  web_ui:
    build:
      context: ./services/web_ui
      dockerfile: Dockerfile
    container_name: ai_lite_web_ui
    ports:
      - "3000:3000"
    environment:
      SERVICE_NAME: web_ui
      
      # 单机模式配置 - 所有服务指向本地地址
      QA_SERVICE_URL: http://qa_entry:8000
      PROMPT_SERVICE_URL: http://prompt_service:8000
      RAG_SERVICE_URL: http://rag_service:8000
      AGENT_SERVICE_URL: http://agent_service:8000
      INTEGRATION_SERVICE_URL: http://integration:8000
      LLM_SERVICE_URL: http://llm_service:8000
      
      # 日志级别
      LOG_LEVEL: INFO
      
      # 数据库配置 - 使用 SQLite
      DB_PATH: /app/data/web_ui.db
    
    volumes:
      # 持久化数据（用户、会话、Q&A 历史）
      - ./data/web_ui:/app/data
      # 挂载静态文件以支持热更新
      - ./services/web_ui/static:/app/static
    
    networks:
      - ai_lite_net
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    
  # ==================== 微服务（可选，需要 --profile all 启动）====================
  
  # QA Entry Service - 问答入口
  qa_entry:
    build:
      context: ./services/qa_entry
      dockerfile: Dockerfile.lite
    container_name: ai_lite_qa_entry
    ports:
      - "8001:8000"
    environment:
      SERVICE_NAME: qa_entry
      LITE_MODE: "true"
      PROMPT_SERVICE_URL: http://prompt_service:8000
      RAG_SERVICE_URL: http://rag_service:8000
      AGENT_SERVICE_URL: http://agent_service:8000
      LLM_SERVICE_URL: http://llm_service:8000
      LOG_LEVEL: INFO
    networks:
      - ai_lite_net
    restart: unless-stopped
    profiles: ["all", "services"]

  # Prompt Service - Prompt管理层
  prompt_service:
    build:
      context: ./services/prompt_service
      dockerfile: Dockerfile.lite
    container_name: ai_lite_prompt_service
    ports:
      - "8002:8000"
    environment:
      SERVICE_NAME: prompt_service
      LITE_MODE: "true"
      LOG_LEVEL: INFO
    networks:
      - ai_lite_net
    restart: unless-stopped
    profiles: ["all", "services"]

  # RAG Service - RAG知识库（轻量版）
  rag_service:
    build:
      context: ./services/rag_service
      dockerfile: Dockerfile.lite
    container_name: ai_lite_rag_service
    ports:
      - "8003:8000"
    environment:
      SERVICE_NAME: rag_service
      LITE_MODE: "true"
      LOG_LEVEL: INFO
    volumes:
      - ./data/documents:/app/data
    networks:
      - ai_lite_net
    restart: unless-stopped
    profiles: ["all", "services"]

  # Agent Service - Agent执行层
  agent_service:
    build:
      context: ./services/agent_service
      dockerfile: Dockerfile.lite
    container_name: ai_lite_agent_service
    ports:
      - "8004:8000"
    environment:
      SERVICE_NAME: agent_service
      LITE_MODE: "true"
      LOG_LEVEL: INFO
    networks:
      - ai_lite_net
    restart: unless-stopped
    profiles: ["all", "services"]

  # Integration Service - 企业系统集成（轻量版）
  integration:
    build:
      context: ./services/integration
      dockerfile: Dockerfile.lite
    container_name: ai_lite_integration
    ports:
      - "8005:8000"
    environment:
      SERVICE_NAME: integration
      LITE_MODE: "true"
      LOG_LEVEL: INFO
    networks:
      - ai_lite_net
    restart: unless-stopped
    profiles: ["all", "services"]

  # LLM Service - 大模型接口 (支持OpenAI和ChatAnywhere)
  llm_service:
    build:
      context: ./services/llm_service
      dockerfile: Dockerfile.lite
    container_name: ai_lite_llm_service
    ports:
      - "8006:8000"
    environment:
      SERVICE_NAME: llm_service
      LITE_MODE: "true"
      LOG_LEVEL: INFO
      # LLM提供商: openai 或 chatanywhere
      LLM_PROVIDER: ${LLM_PROVIDER:-openai}
      # OpenAI配置
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      OPENAI_API_URL: ${OPENAI_API_URL:-https://api.openai.com/v1}
      # ChatAnywhere配置
      CHATANYWHERE_API_KEY: ${CHATANYWHERE_API_KEY:-}
      CHATANYWHERE_API_URL: ${CHATANYWHERE_API_URL:-https://api.chatanywhere.com.cn/v1}
      # 默认模型
      LLM_MODEL: ${LLM_MODEL:-gpt-3.5-turbo}
    networks:
      - ai_lite_net
    restart: unless-stopped
    profiles: ["all", "services"]

networks:
  ai_lite_net:
    driver: bridge
