# AI Common Platform 调用链追踪系统 - 快速演示指南

## 🚀 快速开始

### 1. 启动系统（如果还未启动）
```bash
cd /Users/zhao_/Documents/保乐力加/AI实践/AICommonPlatform
docker-compose -f docker-compose.lite.yml up -d
```

### 2. 打开 Web UI
访问: **http://localhost:3000**

### 3. 启用调用链追踪
在"问答"页面的输入框下方，勾选 **"📊 显示调用链"** 复选框

---

## 📊 核心演示场景

### 场景 1: 理解 RAG 架构（初级学者）

**提问**: "什么是检索增强生成(RAG)?"

**观看重点**:
1. **第3-5步**: 知识检索阶段
   - 看到问题如何被向量化
   - 向量搜索在 Milvus 中如何工作
   - 全文搜索在 Elasticsearch 中的并行执行

2. **第6-7步**: 上下文增强
   - 系统如何从企业数据库获取补充数据
   - 权限校验的作用

3. **第8-10步**: Prompt 工程和 LLM 调用
   - 选定的角色和模板版本
   - 选择的 LLM 模型（为什么选择 GPT-4）
   - 生成参数设置

**学习收获**:
- 📚 理解现代 AI 系统的"增强"机制
- 🔍 向量搜索 vs 关键词搜索的区别
- 🎯 Prompt 工程的重要性

---

### 场景 2: 学习企业系统集成（中级学者）

**提问**: "我们公司今年第一季度的销售数据如何?"

**观看重点**:
1. **第2步**: 意图识别
   - 系统识别出"数据查询"意图
   - 自动提取"销售"和"时间"关键词

2. **第6步**: 数据查询
   - `Integration Service (ERP)` 调用
   - `query_type: "sales_report"`
   - `period: "Q1"`

3. **第7步**: 权限校验
   - 用户角色 (analyst)
   - 访问权限是否批准

4. **第11步**: 结果处理
   - 添加 5 个参考文献
   - 置信度评分 0.92

**学习收获**:
- 💼 如何安全地查询企业系统
- 🔐 数据权限管理的必要性
- 📈 多源数据融合的工作流程

---

### 场景 3: 探索 LLM 模型选择（高级学者）

**提问**: "如何使用 Agent 实现自动化业务流程?"

**观看重点**:
1. **第9步**: LLM 模型选择
   - 显示的选定模型
   - 为什么选择该模型
   - 备选模型列表

2. **第10步**: API 调用详情
   - 生成参数 (temperature, max_tokens)
   - Token 使用统计

3. **整体执行流程**:
   - 完整的 12 个处理步骤
   - 每步的执行时间
   - 总体响应时间

**学习收获**:
- 🤖 多 LLM 模型支持的架构设计
- ⚙️ 生成参数对结果的影响
- 📊 Token 计费和成本优化

---

## 🏗️ 架构学习模式

### 打开方式
点击侧边栏的 **"🏗️ 查看 AI 架构"** 按钮

### 包含内容

#### 平台概览
```
AI Common Platform v1.0.0
微服务架构 | RAG + Agent + LLM 模式支持
```

#### 8个核心处理阶段（含详细说明）

**Stage 1: 输入处理 (Input Processing)**
- 服务: QA Entry Service
- 目的: 接收和预处理用户输入
- 技术: NLP预处理、文本清洗
- 数据源: 用户输入

**Stage 2: 意图识别 (Intent Recognition)**
- 服务: QA Entry Service
- 目的: 理解用户真实意图
- 技术: 文本分类、实体识别、关键词提取
- 数据源: 清洗后的问题文本

**Stage 3: 知识检索 (RAG - Retrieval Augmented Generation)**
- 服务: RAG Service
- 目的: 从知识库检索相关信息
- 技术: 
  - 向量化 (Embeddings)
  - 向量搜索 (Milvus - 百万级数据)
  - 全文搜索 (Elasticsearch)
- 数据源: Milvus、Elasticsearch、PostgreSQL

**Stage 4: 上下文增强 (Context Enhancement)**
- 服务: Agent Service、Integration Service
- 目的: 获取实时企业数据
- 技术: API调用、数据融合、权限管理
- 数据源: ERP、CRM、HRM、财务系统

**Stage 5: Prompt 工程 (Prompt Engineering)**
- 服务: Prompt Service
- 目的: 设计高效的提示词
- 技术: 
  - 角色系统 (销售、HR、技术、财务顾问)
  - Few-shot学习
  - Chain-of-Thought推理
- 上下文长度: 2048 tokens

**Stage 6: LLM 推理 (LLM Inference)**
- 服务: LLM Service
- 目的: 生成高质量回答
- 支持的模型:
  - OpenAI: GPT-4, GPT-3.5-turbo
  - 阿里: 通义千问 (Qwen)
  - 百度: 文心一言 (Ernie)
  - 科大讯飞: 讯飞星火 (SparkDesk)
  - 智谱: GLM-4
- 参数: temperature 0.7, max_tokens 1024

**Stage 7: 结果处理 (Post-processing)**
- 服务: QA Entry Service
- 目的: 格式化和优化结果
- 技术: 
  - 置信度评分
  - 参考文献整理
  - 数据脱敏

**Stage 8: 响应返回 (Response)**
- 服务: Web UI Service
- 目的: 返回最终答案和元数据
- 包含: 完整调用链、执行时间、置信度等

#### 关键技术栈

**自然语言处理 (NLP)**
- jieba (分词)
- NLTK (文本处理)
- Transformers (深度学习模型)

**向量化与存储**
- Word2Vec / BERT (向量表示)
- Milvus (向量数据库 - 百万级规模)
- Pinecone (备选)

**全文搜索**
- Elasticsearch (支持中文分词、复杂查询)
- 倒排索引 (高效关键词查询)

**数据存储**
- PostgreSQL (关系数据)
- Redis (缓存、会话)
- MongoDB (灵活的文档存储)

**LLM 集成**
- 多源 API 调用
- Token 管理和计费
- 流式传输支持
- 模型评估和选择

**系统架构**
- FastAPI (高性能异步框架)
- Docker (容器化部署)
- Kubernetes (可选的编排)
- Redis + RabbitMQ (消息队列)

---

## 🔍 追踪数据解读

### 追踪链的关键字段

```json
{
  "trace_id": "048449e0",           // 唯一的追踪 ID，用于追踪整个请求
  "question": "测试问题",            // 原始问题
  "total_steps": 12,                // 总共 12 个处理步骤
  "total_time": "0.002s",           // 总执行时间
  "steps": [
    {
      "seq": 1,                     // 步骤序号
      "timestamp": "...",           // 执行时间戳
      "stage": "输入处理",          // 处理阶段名称
      "service": "QA Entry Service", // 调用的服务
      "purpose": "...",             // 这一步的用途
      "status": "success",          // 执行状态 (success/error/skip)
      "data": {                     // 此步的具体数据
        "raw_question": "..."
      }
    },
    // ... 更多步骤
  ],
  "architecture_description": "..."  // 整个架构说明
}
```

### 关键指标解读

| 指标 | 说明 | 优化方向 |
|------|------|---------|
| **total_time** | 整个问答耗时 | 如果 > 1s，检查哪个步骤耗时长 |
| **total_steps** | 处理步骤数 | 步骤越少通常速度越快（但可能准确度降低） |
| **similar_docs** | 检索出的相似文档数 | 增加可能提高准确度，但也增加成本 |
| **selected_model** | 选择的 LLM 模型 | 更强大的模型通常更慢更贵 |
| **tokens_used** | Token 使用数 | 对应的 API 调用成本 |

---

## 💡 学习技巧

### Tip 1: 对比不同的问题
提问同一个内容的不同表述方式，观察意图识别的差异：
- "什么是 RAG?" vs "如何使用检索增强生成?"
- "销售数据" vs "第一季度销售报告"

### Tip 2: 观察模型选择
通过提问不同复杂度的问题，观察系统如何选择 LLM 模型：
- 简单问题 → 可能选择更轻量的模型
- 复杂问题 → 选择 GPT-4 等更强大的模型

### Tip 3: 追踪权限校验
在获取企业数据的步骤中，注意权限校验的结果：
```json
{
  "user_role": "analyst",
  "approved": true  // 检查用户是否有权限
}
```

### Tip 4: 理解上下文融合
观察系统如何组合不同数据源的信息：
- 知识库 (RAG) → 来自企业内部文档
- 企业系统 (ERP) → 来自实时业务系统
- LLM → 提供智能理解和生成

### Tip 5: 性能优化的思路
通过追踪数据，识别可以优化的地方：
- 缓存常见问题的检索结果
- 并行执行向量搜索和全文搜索
- 为常用查询预编译 SQL

---

## 🎓 深度学习路线

### 第 1 天: 基础理解
- [ ] 学习 8 个处理阶段的含义
- [ ] 运行 3-5 个示例问题，观看追踪链
- [ ] 阅读 TRACE_GUIDE.md

### 第 2 天: 技术细节
- [ ] 学习 RAG 的原理 (向量搜索 vs 全文搜索)
- [ ] 理解 Prompt 工程的关键要素
- [ ] 研究 LLM 模型的选择策略

### 第 3 天: 系统优化
- [ ] 分析不同问题的执行时间差异
- [ ] 理解权限校验和数据安全
- [ ] 探索缓存和并行优化

### 第 4 天: 高级应用
- [ ] 修改 Prompt 模板，观看结果变化
- [ ] 调整检索参数，观察准确度变化
- [ ] 设计自定义的 Agent 工具

---

## 📋 常见问题解答

### Q: 为什么有时候步骤数不同？
**A:** 系统会根据问题的复杂度动态调整步骤：
- 简单问题可能跳过某些步骤
- 复杂问题需要更多的处理步骤

### Q: "total_time" 通常多长？
**A:** 
- 缓存命中: 10-100ms
- 普通问题: 200-500ms  
- 复杂问题: 500ms-2s

### Q: 如何选择合适的 LLM 模型？
**A:** 平台会自动选择，考虑因素包括：
- 问题复杂度
- 成本预算
- 响应时间要求
- 模型可用性

### Q: 如何降低成本（Token 使用数）？
**A:**
- 提更简洁、清晰的问题
- 增加缓存命中率
- 使用更轻量的 LLM 模型
- 减少检索的文档数量

### Q: RAG 检索的相关性如何评估？
**A:** 通过观察：
- `similar_docs`: 检索到的文档数
- 返回答案的 `confidence`: 置信度评分
- 参考文献数量和质量

---

## 🚀 下一步

1. **启动系统**: ✅ 已完成
2. **打开 Web UI**: 访问 http://localhost:3000
3. **启用追踪**: 勾选"显示调用链"
4. **开始探索**: 提问并观看完整的处理流程
5. **深入学习**: 基于追踪链理解 AI 架构

---

**记住**: 每条追踪链都是一次完整的学习机会。通过观察真实的数据流，你将更深刻地理解现代 AI 系统的工作原理！🎓

