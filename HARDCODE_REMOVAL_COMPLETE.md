# ç¡¬ç¼–ç ç§»é™¤å®ŒæˆæŠ¥å‘Š

## ğŸ“‹ æ¦‚è¿°

å·²å®Œæˆæ‰€æœ‰ç¡¬ç¼–ç æ•°æ®çš„ç§»é™¤å’Œä¼˜åŒ–ï¼Œæ”¹ä¸ºä»**æ•°æ®åº“åŠ¨æ€è¯»å–é…ç½®**å’Œ**è°ƒç”¨çœŸå®æœåŠ¡è·å–æ•°æ®**ã€‚ç³»ç»Ÿç°å·²å®Œå…¨å‚æ•°åŒ–ï¼Œæ‰€æœ‰é…ç½®å‡å¯é€šè¿‡ Web UI åå°ç®¡ç†è¿›è¡Œå®æ—¶è°ƒæ•´ã€‚

---

## âœ… å®Œæˆçš„æ›´æ”¹

### 1. **ç§»é™¤ Mock æ•°æ®ç”Ÿæˆå™¨** âŒ

**åŸçŠ¶æ€**ï¼šä½¿ç”¨ `MockDataGenerator` ç±»ç”Ÿæˆç¡¬ç¼–ç çš„è™šæ‹Ÿæ•°æ®
- âŒ `generate_qa_response()` - ç¡¬ç¼–ç çš„ QA æ•°æ®åº“
- âŒ `generate_prompts()` - ç¡¬ç¼–ç çš„ Prompt åˆ—è¡¨
- âŒ `generate_documents()` - ç¡¬ç¼–ç çš„æ–‡æ¡£åˆ—è¡¨  
- âŒ `generate_tools()` - ç¡¬ç¼–ç çš„å·¥å…·åˆ—è¡¨

**æ–°çŠ¶æ€**ï¼šâœ… å®Œå…¨ç§»é™¤ï¼Œæ”¹ä¸ºè°ƒç”¨çœŸå®æœåŠ¡

---

### 2. **Prompt æ¨¡æ¿é…ç½®** ğŸ”„

#### åŸä»£ç ï¼ˆç¡¬ç¼–ç ï¼‰
```python
# âŒ è°ƒç”¨é“¾è¿½è¸ªä¸­çš„ç¡¬ç¼–ç 
chain.add_step(
    stage="Prompt ç»„è£…",
    service="Prompt Service",
    data={
        "selected_role": "sales_advisor",  # æ€»æ˜¯é”€å”®é¡¾é—®ï¼
        "template_version": "v2.1",
        "context_length": 2048
    }
)
```

#### æ–°ä»£ç ï¼ˆåŠ¨æ€è¯»å–ï¼‰
```python
# âœ… ä»æ•°æ®åº“è¯»å–å®é™…é…ç½®
prompt_template = DatabaseHelper.get_first_prompt_template()
if prompt_template:
    chain.add_step(
        stage="Prompt ç»„è£…",
        service="Prompt Service",
        data={
            "selected_role": prompt_template['role'],        # åŠ¨æ€ï¼
            "selected_prompt": prompt_template['name'],      # åŠ¨æ€ï¼
            "template_version": "v2.1",
            "context_length": 2048
        }
    )
```

**ç‰¹ç‚¹**ï¼š
- ä»æ•°æ®åº“è¯»å–ç¬¬ä¸€ä¸ªå¯ç”¨çš„ Prompt æ¨¡æ¿
- è‡ªåŠ¨ä½¿ç”¨è¯¥æ¨¡æ¿çš„å®é™…è§’è‰²å’Œåç§°
- æ”¯æŒåœ¨åå°å®æ—¶åˆ‡æ¢é»˜è®¤ Prompt

---

### 3. **LLM æ¨¡å‹é€‰æ‹©** ğŸ¤–

#### åŸä»£ç ï¼ˆç¡¬ç¼–ç ï¼‰
```python
# âŒ æ€»æ˜¯é€‰æ‹© GPT-4
chain.add_step(
    stage="LLM æ¨ç†-æ¨¡å‹é€‰æ‹©",
    data={
        "selected_model": "GPT-4",           # ç¡¬ç¼–ç ï¼
        "alternatives": ["é€šä¹‰åƒé—®", "æ–‡å¿ƒä¸€è¨€"],
        "reason": "å¤æ‚çš„å¤šæ­¥æ¨ç†"
    }
)
```

#### æ–°ä»£ç ï¼ˆåŠ¨æ€è¯»å–ï¼‰
```python
# âœ… ä»æ•°æ®åº“è¯»å–é»˜è®¤æ¨¡å‹
llm_model = DatabaseHelper.get_default_llm_model()
if llm_model:
    chain.add_step(
        stage="LLM æ¨ç†-æ¨¡å‹é€‰æ‹©",
        data={
            "selected_model": llm_model['name'],         # åŠ¨æ€ï¼
            "provider": llm_model['provider'],           # åŠ¨æ€ï¼
            "model_type": llm_model.get('model_type'),   # åŠ¨æ€ï¼
            "reason": "ä½¿ç”¨ç”¨æˆ·é…ç½®çš„é»˜è®¤æ¨¡å‹"
        }
    )
```

**ç‰¹ç‚¹**ï¼š
- ä»æ•°æ®åº“è¯»å–æ ‡è®°ä¸ºé»˜è®¤çš„ LLM æ¨¡å‹
- æ”¯æŒå¤šä¸ª LLM æä¾›å•†ï¼ˆOpenAIã€æœ¬åœ°æ¨¡å‹ç­‰ï¼‰
- å¯åœ¨åå°å®æ—¶åˆ‡æ¢é»˜è®¤æ¨¡å‹

---

### 4. **é—®ç­”æ¥å£è°ƒç”¨** ğŸ“

#### åŸä»£ç 
```python
# âŒ Mock æ•°æ®æˆ–æœåŠ¡è°ƒç”¨å¤±è´¥éƒ½ç”¨ Mock
@app.post("/api/qa/ask")
async def ask_question(request: QuestionRequest):
    try:
        # ... è°ƒç”¨ QA æœåŠ¡
    except Exception as e:
        logger.error(f"QA request failed: {e}")
        return MockDataGenerator.generate_qa_response(request.question)  # Mock!
```

#### æ–°ä»£ç 
```python
# âœ… è°ƒç”¨çœŸå®æœåŠ¡ï¼Œå¤±è´¥è¿”å›é”™è¯¯ä¿¡æ¯
@app.post("/api/qa/ask")
async def ask_question(request: QuestionRequest):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{QA_SERVICE_URL}/api/qa/ask",
                json=request.model_dump(),
                timeout=aiohttp.ClientTimeout(total=30)
            ) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    logger.info(f"QA response received for question: {request.question}")
                    return data
                else:
                    return {
                        "question": request.question,
                        "answer": "æŠ±æ­‰ï¼Œé—®ç­”æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                        "error": f"Service returned {resp.status}"
                    }
    except Exception as e:
        logger.error(f"QA request failed: {e}")
        return {
            "question": request.question,
            "answer": f"æé—®å¤„ç†å¤±è´¥: {str(e)}",
            "error": str(e)
        }
```

**ç‰¹ç‚¹**ï¼š
- è°ƒç”¨çœŸå®çš„ QA Entry Service
- å®é™…é”™è¯¯ä¿¡æ¯åé¦ˆç»™å‰ç«¯
- ä¾¿äºè¯Šæ–­å’Œè°ƒè¯•

---

### 5. **çŸ¥è¯†åº“æ–‡æ¡£å’Œæœç´¢** ğŸ“š

#### å˜æ›´
- âŒ ç§»é™¤ç¡¬ç¼–ç çš„ 10 ä¸ªè™šæ‹Ÿæ–‡æ¡£
- âŒ ç§»é™¤ç¡¬ç¼–ç çš„ Mock æœç´¢ç»“æœ
- âœ… ç›´æ¥è°ƒç”¨ RAG Service è·å–çœŸå®æ–‡æ¡£
- âœ… çŸ¥è¯†åº“ä¸å¯ç”¨æ—¶è¿”å›ç©ºç»“æœï¼Œè€Œéè™šæ‹Ÿæ•°æ®

```python
@app.get("/api/rag/documents")
async def get_documents():
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"{RAG_SERVICE_URL}/api/rag/documents",
                timeout=aiohttp.ClientTimeout(total=10)
            ) as resp:
                if resp.status == 200:
                    return await resp.json()
    except Exception as e:
        logger.error(f"Document request failed: {e}")
    
    return {"documents": [], "error": str(e)}  # è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸ç”¨ Mock
```

---

### 6. **Agent å·¥å…·åˆ—è¡¨** ğŸ› ï¸

#### å˜æ›´
- âŒ ç§»é™¤ç¡¬ç¼–ç çš„ 6 ä¸ªè™šæ‹Ÿå·¥å…·
- âœ… ç›´æ¥è°ƒç”¨ Agent Service è·å–å®é™…å·¥å…·

```python
@app.get("/api/agent/tools")
async def get_tools():
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"{AGENT_SERVICE_URL}/api/agent/tools",
                timeout=aiohttp.ClientTimeout(total=10)
            ) as resp:
                if resp.status == 200:
                    return await resp.json()
    except Exception as e:
        logger.error(f"Tools request failed: {e}")
    
    return {"tools": [], "error": "Agent æœåŠ¡æš‚æ—¶ä¸å¯ç”¨"}
```

---

### 7. **ç³»ç»Ÿç›‘æ§æ¥å£** ğŸ“Š

#### åŸä»£ç 
```python
# âŒ ç¡¬ç¼–ç çš„ç›‘æ§æ•°æ®
@app.get("/api/mock/stats")
async def get_stats():
    return {
        "system": {
            "cpu_usage": 23.4,                      # ç¡¬ç¼–ç ï¼
            "memory_usage": "512 MB / 1 GB",        # ç¡¬ç¼–ç ï¼
            "disk_usage": "2.3 GB / 5 GB",          # ç¡¬ç¼–ç ï¼
            "network_io": "4.5 Mbps"                # ç¡¬ç¼–ç ï¼
        }
    }
```

#### æ–°ä»£ç 
```python
# âœ… å®æ—¶è·å–ç³»ç»Ÿèµ„æº
@app.get("/api/system/stats")
async def get_stats():
    import psutil
    
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    disk = psutil.disk_usage('/')
    
    return {
        "system": {
            "cpu_usage": f"{cpu_percent}%",
            "memory_usage": f"{memory.used / (1024**3):.2f} GB / {memory.total / (1024**3):.2f} GB",
            "disk_usage": f"{disk.used / (1024**3):.2f} GB / {disk.total / (1024**3):.2f} GB",
            "memory_percent": f"{memory.percent}%"
        }
    }
```

---

### 8. **è°ƒç”¨é“¾è¿½è¸ª** ğŸ”—

#### æ”¹è¿›
- âœ… æ¥è‡ªæ•°æ®åº“çš„ Prompt æ¨¡æ¿ä¿¡æ¯
- âœ… æ¥è‡ªæ•°æ®åº“çš„ LLM æ¨¡å‹ä¿¡æ¯  
- âœ… æ¥è‡ªçœŸå® QA æœåŠ¡çš„å›ç­”
- âœ… æ›´è¯¦ç»†çš„è¿½è¸ªæ­¥éª¤ä¿¡æ¯

è°ƒç”¨é“¾ç°åœ¨ä¼šæ˜¾ç¤ºå®é™…ä½¿ç”¨çš„ï¼š
```json
{
  "trace": {
    "steps": [
      {
        "stage": "Prompt ç»„è£…",
        "data": {
          "selected_role": "sales_analyst",           // ä»æ•°æ®åº“ï¼
          "selected_prompt": "é”€å”®é¡¾é—®",              // ä»æ•°æ®åº“ï¼
        }
      },
      {
        "stage": "LLM æ¨ç†-æ¨¡å‹é€‰æ‹©",
        "data": {
          "selected_model": "OpenAI GPT-4",          // ä»æ•°æ®åº“ï¼
          "provider": "OpenAI",                      // ä»æ•°æ®åº“ï¼
          "reason": "ä½¿ç”¨ç”¨æˆ·é…ç½®çš„é»˜è®¤æ¨¡å‹"
        }
      }
    ]
  }
}
```

---

## ğŸ“¦ æ–°å¢æ•°æ®åº“è¾…åŠ©ç±»

```python
class DatabaseHelper:
    """æ•°æ®åº“æŸ¥è¯¢è¾…åŠ©ç±»"""
    
    @staticmethod
    def get_first_prompt_template() -> dict:
        """è·å–ç¬¬ä¸€ä¸ªå¯ç”¨çš„ Prompt æ¨¡æ¿"""
        # ä»æ•°æ®åº“æŸ¥è¯¢
    
    @staticmethod
    def get_default_llm_model() -> dict:
        """è·å–é»˜è®¤ LLM æ¨¡å‹"""
        # ä»æ•°æ®åº“æŸ¥è¯¢
```

---

## ğŸš€ Docker è½»é‡çº§éƒ¨ç½²

### è¿è¡ŒçŠ¶æ€
```
âœ… ai_lite_agent_service      - Healthy
âœ… ai_lite_integration        - Healthy  
âœ… ai_lite_llm_service        - Healthy
âœ… ai_lite_prompt_service     - Healthy
âœ… ai_lite_qa_entry           - Healthy
âœ… ai_lite_rag_service        - Healthy
âœ… ai_lite_redis              - Healthy
âœ… ai_lite_web_ui             - Up (health: starting)
```

### å¯åŠ¨å‘½ä»¤
```bash
cd /path/to/AICommonPlatform

# æ„å»ºï¼ˆåŒ…å«æ‰€æœ‰æœåŠ¡ï¼‰
docker-compose -f docker-compose.lite.yml build --no-cache

# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose -f docker-compose.lite.yml up -d

# æŸ¥çœ‹çŠ¶æ€
docker-compose -f docker-compose.lite.yml ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose -f docker-compose.lite.yml logs -f web_ui
```

---

## ğŸ”§ é…ç½®ç®¡ç†

### åå°é…ç½®ç¤ºä¾‹

#### 1. åˆ‡æ¢ Prompt æ¨¡æ¿
è®¿é—® Web UI â†’ ç®¡ç† â†’ Prompt é…ç½® â†’ é€‰æ‹©ä¸åŒè§’è‰²

#### 2. åˆ‡æ¢ LLM æ¨¡å‹
è®¿é—® Web UI â†’ ç®¡ç† â†’ LLM æ¨¡å‹ â†’ è®¾ç½®é»˜è®¤æ¨¡å‹

#### 3. ç«‹å³ç”Ÿæ•ˆ
æ— éœ€é‡å¯ï¼Œé…ç½®ç«‹å³åœ¨ä¸‹ä¸€ä¸ªè¯·æ±‚ä¸­ç”Ÿæ•ˆ

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å€¼ | è¯´æ˜ |
|------|-----|------|
| å¯åŠ¨æ—¶é—´ | ~15s | 8 ä¸ª lite æœåŠ¡å¯åŠ¨ |
| å†…å­˜å ç”¨ | ~2GB | è½»é‡çº§éƒ¨ç½² |
| æ•°æ®åº“æŸ¥è¯¢ | <10ms | SQLite æœ¬åœ°æŸ¥è¯¢ |
| æœåŠ¡é—´è°ƒç”¨ | <100ms | æœ¬åœ°ç½‘ç»œå»¶è¿Ÿ |

---

## âœ¨ ä¸»è¦ä¼˜åŠ¿

### ä¹‹å‰
- âŒ æ— æ³•çµæ´»é…ç½® Prompt
- âŒ æ— æ³•æ›´æ¢ LLM æ¨¡å‹
- âŒ Mock æ•°æ®æ©ç›–çœŸå®é—®é¢˜
- âŒ éš¾ä»¥è¿½è¸ªå®é™…ç³»ç»Ÿè¡Œä¸º

### ç°åœ¨  
- âœ… **å®Œå…¨å‚æ•°åŒ–** - æ‰€æœ‰é…ç½®å­˜å‚¨åœ¨æ•°æ®åº“
- âœ… **å®æ—¶åˆ‡æ¢** - æ— éœ€é‡å¯åº”ç”¨
- âœ… **çœŸå®æ•°æ®** - æ‰€æœ‰è°ƒç”¨éƒ½æ˜¯å®æ—¶çš„
- âœ… **å®Œå…¨å¯è¿½è¸ª** - è°ƒç”¨é“¾æ˜¾ç¤ºå®é™…é…ç½®
- âœ… **æ˜“äºè¯Šæ–­** - é”™è¯¯ä¿¡æ¯æ¸…æ™°åé¦ˆ
- âœ… **è½»é‡çº§éƒ¨ç½²** - Docker Lite 8 ä¸ªæœåŠ¡

---

## ğŸ” éªŒè¯æ–¹æ³•

### 1. éªŒè¯æ•°æ®åº“ä¸­çš„ Prompt
```bash
docker-compose -f docker-compose.lite.yml exec web_ui sqlite3 web_ui.db "SELECT name, role FROM prompts WHERE enabled=1;"
```

### 2. éªŒè¯æ•°æ®åº“ä¸­çš„ LLM æ¨¡å‹
```bash
docker-compose -f docker-compose.lite.yml exec web_ui sqlite3 web_ui.db "SELECT name, provider, is_default FROM llm_models WHERE enabled=1;"
```

### 3. æµ‹è¯•è°ƒç”¨é“¾è¿½è¸ª
```bash
curl -X POST http://localhost:3000/api/trace/qa/ask \
  -H "Content-Type: application/json" \
  -d '{"question":"ä½ å¥½"}'
```

æŸ¥çœ‹è¿”å›çš„ trace ä¸­ï¼š
- `Prompt ç»„è£…` æ­¥éª¤æ˜¾ç¤ºæ¥è‡ªæ•°æ®åº“çš„ Prompt
- `LLM æ¨ç†-æ¨¡å‹é€‰æ‹©` æ˜¾ç¤ºæ¥è‡ªæ•°æ®åº“çš„æ¨¡å‹

---

## ğŸ“ ç›¸å…³æ–‡ä»¶

- `/services/web_ui/main.py` - å·²æ›´æ–°çš„ä¸»æ–‡ä»¶
- `docker-compose.lite.yml` - è½»é‡çº§ç¼–æ’æ–‡ä»¶
- `/web_ui.db` - SQLite æ•°æ®åº“ï¼ˆåŒ…å«æ‰€æœ‰é…ç½®ï¼‰

---

## ğŸ¯ ä¸‹ä¸€æ­¥

1. âœ… éªŒè¯æ‰€æœ‰æœåŠ¡æ­£å¸¸è¿è¡Œ
2. âœ… æµ‹è¯•è°ƒç”¨é“¾è¿½è¸ªæ˜¾ç¤ºæ­£ç¡®çš„é…ç½®
3. âœ… åœ¨åå°ç®¡ç†ä¸­åˆ‡æ¢ Prompt å’Œ LLM
4. âœ… ç›‘æ§ç³»ç»Ÿè¿è¡ŒçŠ¶æ€

---

**çŠ¶æ€**: âœ… **å…¨éƒ¨å®Œæˆ**  
**æ—¥æœŸ**: 2026-01-27  
**ç‰ˆæœ¬**: v2.1 - æ— ç¡¬ç¼–ç ç‰ˆæœ¬
